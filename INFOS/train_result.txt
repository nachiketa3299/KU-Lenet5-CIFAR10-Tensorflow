batch_size	activation_function	weight__initialization	optimizer	starter_learning_rate	num_epochs	keep_prob	l2_reg_lambda	data_augmentation	learning_rate_decay_rate	learning_rate_decay_step	training_time	early_stopping_epoch	accuracy	timstamp
128	relu	0.01	adam	0.001	100	0.9	0.0	False	1.0	0	34.09670598506928	33250	0.5788000226020813	1601127452
128	relu	0.01	adam	0.001	100	0.9	0.0001	False	1.0	0	33.09599237839381	30100	0.6015999913215637	1601129504
128	relu	0.01	adam	0.001	100	0.9	0.0001	True	1.0	0	37.37066901922226	35000	0.6480000019073486	1601131496
128	relu	he	adam	0.001	100	0.9	0.0001	True	0.96	5000	38.969384002685544	28700	0.6478000283241272	1601133755
128	relu	he	adam	0.001	100	0.9	0.0001	True	0.98	5000	36.663212704658505	32200	0.6481999754905701	1601159766
128	relu	he	adam	0.001	100	0.9	0.0001	True	0.94	5000	37.622000726064044	33950	0.652400016784668	1601161971
128	relu	he	adam	0.001	100	0.9	0.0001	True	0.92	5000	39.067410838603976	34300	0.6478000283241272	1601165698
128	relu	he	adam	0.001	100	0.9	0.0001	True	0.9	5000	37.71315077145894	33600	0.645799994468689	1601168052

128	relu	he	adam	0.001	100	0.9	0.0001	True	0.88	5000	37.534243102868395	27300	0.6636000275611877	1601174672
128	relu	he	adam	0.001	100	0.9	0.0001	True	0.9	10000	37.28126264015834	33600	0.65420001745224	1601178658
